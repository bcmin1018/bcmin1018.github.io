---
layout: single
title: "[Pytorch] nn.Embedding 함수 알아보기"
categories: deeplearning
tag: [pytorch, deeplearning]
---
파이토치에서 임베딩 레이어를 만들어 훈련 데이터로 부터 임베딩 값을 만들어 줄 수 있다. 데이터를 문자 그래도 넣지 않고 숫자로 치환하는 것이다. 파이토치에서는 torch.nn.Embedding 이라는 함수를 제공하는데 이 것을 사용하면 손쉽게 데이터를 변환해줄 수 있다.

기본적인 사용으로는 아래와 같이 input_size, hidden_size를 인자로 주어 사용할 수 있다. input_size는 보통 훈련데이터의 행의 개수이다. 2000개의 행을 갖는 데이터의 input_size 는 2000개이다. hidden_size는 출력되는 백터의 차원이다. 데이터를 1행을 임베딩 후 Output으로 몇차원의 벡터로 나오게 할 건지 설정한다. 만약 hidden_size가 256이면 256개의 차원으로 임베딩 된다.

```python
embedding = nn.Embedding(input_size, hidden_size)
```
2000개의 input을 입력하고 한개의 input당 256개의 벡터 사이즈로 변환한다.
```python
OutPut: Embedding(2000, 256)
```
변환된 데이터를 살펴보면 256 차원으로 변환된 것을 확인 할 수 있다.
```python
embedding = embedding.weight
embedding[0]
```
```python
tensor([ 2.4344e-01,  6.3803e-01, -2.7388e-01,  1.8423e-02, -3.2423e+00,
         1.8230e-01,  1.1029e-01,  7.2603e-02, -1.3892e+00, -4.3728e-01,
         6.0645e-01, -2.0083e-01, -1.6052e+00,  7.2701e-01,  9.1952e-01,
        -3.1036e-01,  4.0860e-01, -1.6729e-01,  2.3748e-01, -4.5469e-02,
         1.9580e+00,  4.9543e-01, -7.8118e-01, -2.0792e+00, -4.5579e-01,
        -2.8842e-01,  1.0836e+00,  4.2190e-01, -3.9766e-01,  1.0669e+00,
        -1.9460e-01,  3.1791e-01,  1.9030e+00, -3.3034e-01, -6.4369e-02,
         1.2370e+00,  1.3937e-01, -3.2826e-01, -1.6536e+00, -4.5623e-01,
         2.4329e-02,  9.9114e-02,  5.9711e-01, -2.2914e-01, -4.6709e-01,
        -9.0571e-01, -1.0779e+00,  4.4067e-01,  1.4799e+00,  1.9436e-01,
         6.9306e-01,  2.9527e-01,  2.3392e+00, -2.6259e-02,  5.3441e-01,
        -1.3157e+00, -1.7976e+00,  9.7937e-01,  1.5091e+00,  6.1063e-01,
        -1.1011e+00, -2.4159e-03,  6.1931e-01,  6.2339e-01, -2.4477e+00,
        -1.8312e+00,  2.4852e-01,  9.0782e-01,  7.4356e-01, -2.4429e-01,
        -1.4642e+00, -7.2466e-01, -8.4472e-01,  1.1131e-01, -9.5472e-02,
        -8.4346e-01, -6.7120e-01,  3.0118e-01, -7.5125e-01, -1.0119e-01,
         7.7538e-01,  1.2880e+00,  4.0450e-01,  4.5111e-01,  1.8798e-01,
        -3.7812e-01,  2.1097e-01, -8.6045e-01,  2.8892e-01, -1.0128e-01,
         1.3125e-01,  4.6241e-01,  1.4887e+00, -5.9690e-01,  2.0969e-01,
         2.1451e+00,  3.2669e-02, -6.6628e-01, -4.6471e-01,  2.9013e-01,
        -7.2821e-02,  9.0815e-01, -3.1814e-01,  6.8440e-01, -1.1320e+00,
        -1.3341e+00,  9.7155e-01,  7.7549e-01,  1.3895e-01,  2.0380e+00,
         2.2874e+00,  4.8693e-03,  9.4585e-01, -8.9689e-02,  5.5589e-01,
         1.1469e-04,  5.5273e-01,  2.8781e-01,  3.7004e-01, -3.8269e-01,
        -7.7846e-01, -5.0901e-01, -9.8308e-01, -1.7427e+00,  8.2195e-01,
        -2.0126e+00,  9.0541e-01, -5.5489e-01,  3.0360e-01, -8.2394e-01,
        -1.5709e+00,  1.8670e+00, -3.4441e-01, -1.2361e+00, -1.7419e+00,
         5.4648e-01, -1.1503e+00,  2.0180e+00, -5.7287e-02, -3.0334e-02,
         1.6613e-02, -1.0237e+00,  9.3395e-02,  1.5943e-01,  4.7633e-01,
        -6.6479e-01,  2.1879e-01,  1.2695e+00,  1.1362e+00,  5.5636e-02,
         3.1648e-01, -1.4085e-01, -1.9295e+00, -3.2117e-01,  9.1127e-01,
         7.9572e-01,  1.3744e+00, -1.7319e-01, -6.4374e-01, -7.0505e-01,
         3.1418e-01,  1.3983e+00, -9.3071e-01, -3.1936e-01, -1.1370e+00,
        -2.0729e+00,  4.7061e-01,  2.2566e+00,  4.4568e-01, -1.7514e+00,
         6.5227e-01,  7.7013e-02,  1.2901e-01, -1.1529e+00,  8.0361e-01,
        -5.7525e-01, -8.7057e-01,  5.0818e-01,  7.3593e-01, -1.0767e+00,
        -2.7796e+00,  7.1418e-01,  1.6678e+00, -3.0811e-01,  1.4653e+00,
        -1.6887e-01, -6.0170e-01,  1.3608e+00, -2.8099e-01,  7.5031e-01,
        -6.8683e-01,  1.0415e-01,  7.2916e-01, -5.8471e-01, -9.7763e-01,
         1.2685e-01,  1.2508e+00, -8.5408e-01, -1.3733e+00, -5.4753e-01,
         1.3766e+00,  1.1005e+00, -9.7203e-01,  9.3779e-01, -1.7669e+00,
        -2.5603e-01,  8.9037e-01,  9.0278e-01, -1.1751e+00, -2.7689e-02,
         6.1725e-01,  3.0898e-01,  1.5860e+00, -3.6475e-03, -8.3700e-02,
         2.6931e-01, -1.1121e+00, -3.5768e-02, -8.4119e-01, -1.5943e+00,
         2.7842e-01, -2.6526e-02, -2.6736e-01, -6.2913e-01, -1.0696e+00,
        -4.5144e-02,  3.8508e-01,  1.1341e+00, -5.6682e-01, -6.1805e-02,
        -2.4800e+00,  5.3608e-01,  8.8330e-01,  6.6706e-02,  7.7316e-01,
        -8.6828e-01, -4.7103e-02,  4.5685e-01, -3.0128e-01, -1.1148e+00,
         6.0685e-01, -1.0701e+00, -1.0408e+00, -6.8455e-01,  5.8700e-02,
        -4.0305e-01,  1.8109e-01,  1.0598e+00, -8.3052e-01, -8.9159e-01,
         8.2695e-02,  1.2499e+00, -2.0809e+00,  1.3165e+00,  1.3734e+00,
         1.8870e-01], grad_fn=<SelectBackward0>)
```